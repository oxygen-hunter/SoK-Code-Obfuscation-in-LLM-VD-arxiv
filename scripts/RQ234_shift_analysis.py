import sys
import os

import numpy as np
from adjustText import adjust_text


# æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from utils.constants import SERIES_GROUPS, REASONING_GROUPS, LLM_ABBR_MAPPING, LLM_SIZE_MAPPING

# # å…¨å±€å­—ä½“å¤§å°è®¾ç½®
# plt.rcParams.update({
#     "font.size": 14,
#     "axes.titlesize": 16,
#     "axes.labelsize": 14,
#     "xtick.labelsize": 12,
#     "ytick.labelsize": 12,
#     "legend.fontsize": 12
# })

# plt.rcParams['font.sans-serif'] = ['SimHei']
# plt.rcParams['axes.unicode_minus'] = False

plt.rcParams.update({
    # å…¨å±€åŸºç¡€å­—å·ï¼ˆè®ºæ–‡é‡Œä¸è¦å¤ªå¤§ï¼‰
    "font.size": 10,
    # åæ ‡è½´æ ‡é¢˜ (xlabel, ylabel)
    "axes.labelsize": 10,
    # åæ ‡è½´æ ‡é¢˜ (plt.title)
    "axes.titlesize": 11,
    # åæ ‡è½´åˆ»åº¦
    "xtick.labelsize": 9,
    "ytick.labelsize": 9,
    # å›¾ä¾‹
    "legend.fontsize": 9,
    # çº¿å®½ã€åæ ‡è½´ç²—ç»†ï¼ˆè®ºæ–‡å›¾æ›´æ¸…æ™°ï¼‰
    "axes.linewidth": 0.8,
    "lines.linewidth": 1.2,
})

# å­—ä½“è®¾ç½®ä¸ºæ— è¡¬çº¿ï¼Œé€‚åˆè‹±æ–‡è®ºæ–‡
plt.rcParams["font.sans-serif"] = ["Arial", "DejaVu Sans"]
plt.rcParams["axes.unicode_minus"] = True  # è‹±æ–‡ç¯å¢ƒæ­£å¸¸æ˜¾ç¤ºè´Ÿå·

# é¢œè‰²è®¾ç½®todo
COLOR_STYLE = {
    'upgrade': 'seagreen',
    'degrade': 'tomato',
    'ori': 'skyblue',
    'obf': 'lightcoral',
    'diff': 'slateblue',
}

HATCH_STYLE = {
    'upgrade': '//',
    'degrade': '\\',
    'ori': 'xx',
    'obf': '',
    'diff': '',
}

FIGURE_SIZE_DUAL = (7, 3)  # å®½, é«˜
FIGURE_SIZE_TRI = (3.5,2)


csv_path = "RQs/RQ6_score_shift/score_shift_cases.csv"
output_dir = "RQs/RQ6_score_shift/plots"
os.makedirs(output_dir, exist_ok=True)

# è¯»å…¥æ•°æ®
df = pd.read_csv(csv_path)

# ---------------------------
# æ„é€ æ¨¡å‹åˆ° group æ˜ å°„
# ---------------------------
model_to_group = {}
for series_name, groups in REASONING_GROUPS.items():
    for g_type, models in groups.items():
        for m in models:
            model_to_group[m] = (series_name, g_type)  # è¿”å› (ç³»åˆ—å, æ¨ç†ç±»å‹)

# ---------------------------
# None å‹æ¨¡å‹ç»Ÿä¸€æ”¾åœ¨æœ€å³è¾¹
# ---------------------------
max_size = max([s for s in LLM_SIZE_MAPPING.values() if s is not None])
none_size = max_size + 10  # None æ˜ å°„ä¸ºæ›´é å³çš„ç‚¹

def get_model_size(m):
    return LLM_SIZE_MAPPING[m] if LLM_SIZE_MAPPING[m] is not None else none_size

# ---------------------------
for shift in ["upgrade", "degrade"]:
    df_shift = df[df["shift_type"] == shift]

    if df_shift.empty:
        print(f"âš ï¸ æ²¡æœ‰ä»»ä½• {shift} æ ·æœ¬ï¼")
        continue

    print(f"âœ… {shift} æ ·æœ¬æ•°é‡: {len(df_shift)}")

    # ---------------------------
    # åˆ†æï¼švuln_type
    # ---------------------------
    vuln_counts = df_shift["vuln_type"].value_counts().sort_values(ascending=False).head(20)

    plt.figure(figsize=FIGURE_SIZE_DUAL)  # è½¬ç½®åå®½ > é«˜
    bars = plt.bar(
        vuln_counts.index,  # xè½´ä¸ºæ¼æ´ç±»å‹
        vuln_counts.values,
        color=COLOR_STYLE[shift],
        hatch=HATCH_STYLE[shift],
        edgecolor="black",
    )

    # åœ¨æŸ±å­ä¸Šæ ‡æ•°é‡
    for i, v in enumerate(vuln_counts.values):
        plt.text(i, v + 1, str(v), ha='center', va='bottom')  # æ•°å­—åœ¨æŸ±å­ä¸Šæ–¹

    plt.ylabel(f"{shift} sample count")
    plt.xlabel("vulnerability type")
    plt.xticks(rotation=45, ha='right')  # æ—‹è½¬xè½´æ ‡ç­¾ï¼Œé˜²æ­¢æ‹¥æŒ¤
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"{shift}_by_vuln_type.pdf"))
    plt.close()

    print("âœ… æ¼æ´ç±»å‹åˆ†å¸ƒå›¾å·²ç”Ÿæˆã€‚")


    # ---------------------------
    # ç»Ÿè®¡ä¸åŒ obf combo å¯¼è‡´çš„{shift}æ•°é‡
    # ---------------------------
    combo_counts = df_shift["combo_name"].value_counts().sort_index()

    # ç»˜å›¾
    plt.figure(figsize=FIGURE_SIZE_DUAL)
    bars = plt.bar(
        combo_counts.index, 
        combo_counts.values, 
        color=COLOR_STYLE[shift], 
        hatch=HATCH_STYLE[shift], 
        edgecolor="black"
    )

    # åœ¨æŸ±å­ä¸Šæ ‡æ•°é‡
    for i, v in enumerate(combo_counts.values):
        plt.text(i, v + 0.5, str(v), ha='center')

    plt.xlabel("obfuscation technique")
    plt.ylabel(f"{shift} sample count")
    # plt.title(f"Distribution of {shift} sample on obfuscation technique")
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()

    # ä¿å­˜å›¾è¡¨
    output_path = os.path.join(output_dir, f"{shift}_by_combo.pdf")
    plt.savefig(output_path)
    plt.close()

    print(f"âœ… {shift}åˆ†æå›¾å·²ä¿å­˜åˆ°ï¼š{output_path}")


    # ---------------------------
    # åˆ†æï¼šdatasetï¼ˆè¯­è¨€ï¼‰
    # ---------------------------
    # åˆ†æ¯ï¼šå„æ•°æ®é›†æ€»æ ·æœ¬æ•°
    totals = df.groupby("dataset").size().rename("total")
    # åˆ†å­ï¼šå„æ•°æ®é›†è¯¥ shift çš„æ ·æœ¬æ•°
    counts = df_shift.groupby("dataset").size().rename("count")

    # åˆå¹¶å¾—åˆ° count/total ä¸ ratio
    stats = totals.to_frame().join(counts, how="left").fillna(0)
    stats["count"] = stats["count"].astype(int)
    stats["ratio"] = stats["count"] / stats["total"]

    # æŒ‰æ¯”ä¾‹ä»å¤§åˆ°å°æ’åºï¼Œå¹¶é‡ç½®ç´¢å¼•å¾—åˆ°æœ‰åºçš„ 0..n-1 ä½ç½®
    stats = stats.sort_values("ratio", ascending=False).reset_index()  # åˆ—åŒ…å«: dataset, total, count, ratio

    # å°† x è½´åˆ†ç±»è®¾ä¸ºæœ‰åºç±»åˆ«ï¼Œç¡®ä¿ç»˜å›¾ä¸¥æ ¼æŒ‰æ’åºåçš„é¡ºåº
    stats["dataset"] = pd.Categorical(stats["dataset"], categories=stats["dataset"], ordered=True)

    # ç”»å›¾
    plt.figure(figsize=FIGURE_SIZE_DUAL)
    ax = sns.barplot(data=stats, x="dataset", y="ratio", color=COLOR_STYLE[shift], edgecolor="black", hatch=HATCH_STYLE[shift])

    # åœ¨æŸ±å­ä¸Šæ ‡æ³¨ï¼šcount/total (xx.x%)
    for i, row in stats.iterrows():
        ax.text(
            i, row["ratio"] + 0.01,
            f"{row['count']}/{row['total']} ({row['ratio']*100:.1f}%)",
            ha="center", va="bottom", 
        )

    plt.xlabel("Dataset")
    plt.ylabel(f"{shift} ratio")
    plt.ylim(0, 0.20)
    plt.xticks(rotation=0)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"{shift}_by_dataset.pdf"))
    plt.close()

    print("âœ… æ•°æ®é›†æ¯”ä¾‹å›¾å·²ç”Ÿæˆã€‚")





    # ---------------------------
    # åˆ†æï¼šmodel
    # ---------------------------
    model_counts = df_shift["model"].value_counts().sort_values(ascending=False)

    plt.figure(figsize=FIGURE_SIZE_DUAL)
    bars = plt.bar(
        model_counts.index, 
        model_counts.values, 
        color=COLOR_STYLE[shift], 
        hatch=HATCH_STYLE[shift],
        edgecolor="black"
    )
    # åœ¨æŸ±å­ä¸Šæ ‡æ•°é‡
    for i, v in enumerate(model_counts.values):
        plt.text(i, v + 0.5, str(v), ha='center')

    plt.xlabel("model")
    plt.ylabel(f"{shift} sample count")
    # plt.title(f"Distribution of {shift} sample on models")
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"{shift}_by_model.pdf"))
    plt.close()

    print("âœ… æ¨¡å‹åˆ†å¸ƒå›¾å·²ç”Ÿæˆã€‚")

    


    
    # ---------------------------
    # åˆ†æ LOCï¼ˆæ”¹è¿›ç‰ˆï¼‰
    # ---------------------------
    plt.figure(figsize=FIGURE_SIZE_TRI)

    # å–ä¸¤åˆ—æœ€å°å€¼å’Œæœ€å¤§å€¼
    min_loc = df_shift[["ori_loc", "obf_loc"]].min().min()
    max_loc = df_shift[["ori_loc", "obf_loc"]].max().max()

    # è‡ªåŠ¨ç¡®å®šä¸»è¦åˆ†å¸ƒåŒºé—´ (percentile 1%~99%)
    lower = df_shift[["ori_loc", "obf_loc"]].stack().quantile(0.01)
    upper = df_shift[["ori_loc", "obf_loc"]].stack().quantile(0.99)

    # ç»˜åˆ¶ç›´æ–¹å›¾ + KDE
    sns.histplot(df_shift["ori_loc"], bins=20, kde=True, color=COLOR_STYLE["ori"], hatch = HATCH_STYLE['ori'], alpha=0.6, label="original LOC")
    sns.histplot(df_shift["obf_loc"], bins=20, kde=True, color=COLOR_STYLE["obf"], hatch = HATCH_STYLE['obf'], alpha=0.6, label="obfuscated LOC")

    # è®¾ç½® x è½´æ˜¾ç¤ºä¸»è¦åŒºé—´ï¼Œå‡å°‘ç©ºç™½
    plt.xlim(lower, upper)
    plt.xlabel("Lines of Code (LOC)")
    plt.ylabel("Count")
    plt.legend()
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"{shift}_by_loc.pdf"))
    plt.close()

    # ---------------------------
    # åˆ†æ Complexity
    # ---------------------------
    plt.figure(figsize=FIGURE_SIZE_TRI)

    # è‡ªåŠ¨ç¡®å®šä¸»è¦åˆ†å¸ƒåŒºé—´ (1%~99% åˆ†ä½)
    lower = df_shift[["ori_complexity", "obf_complexity"]].stack().quantile(0.01)
    upper = df_shift[["ori_complexity", "obf_complexity"]].stack().quantile(0.99)

    sns.histplot(df_shift["ori_complexity"], bins=30, kde=True,
                color=COLOR_STYLE['ori'], hatch = HATCH_STYLE['ori'], alpha=0.6, label="original complexity")
    sns.histplot(df_shift["obf_complexity"], bins=30, kde=True,
                color=COLOR_STYLE['obf'], hatch = HATCH_STYLE['obf'], alpha=0.6, label="obfuscated complexity")

    plt.xlim(lower, upper)
    plt.xlabel("Code Complexity")
    plt.ylabel("Count")
    plt.legend()
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"{shift}_by_complexity.pdf"))
    plt.close()

    # ---------------------------
    # LOC å·®å€¼ç›´æ–¹å›¾
    # ---------------------------
    plt.figure(figsize=FIGURE_SIZE_TRI)

    # è‡ªåŠ¨ç¡®å®šä¸»è¦åˆ†å¸ƒåŒºé—´
    loc_diff = df_shift["obf_loc"] - df_shift["ori_loc"]
    lower, upper = loc_diff.quantile([0.01, 0.99])

    sns.histplot(loc_diff, bins=30, kde=True, color=COLOR_STYLE['diff'], hatch = HATCH_STYLE['diff'], alpha=0.6)
    plt.xlim(lower, upper)
    plt.xlabel("LOC Difference (obf - ori)")
    plt.ylabel("Count")
    plt.axvline(0, color="red", linestyle="--", linewidth=1)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"{shift}_by_loc_diff.pdf"))
    plt.close()

    # ---------------------------
    # Complexity å·®å€¼ç›´æ–¹å›¾
    # ---------------------------
    plt.figure(figsize=FIGURE_SIZE_TRI)

    complexity_diff = df_shift["obf_complexity"] - df_shift["ori_complexity"]
    lower, upper = complexity_diff.quantile([0.01, 0.99])

    sns.histplot(complexity_diff, bins=30, kde=True, color=COLOR_STYLE['diff'], hatch = HATCH_STYLE['diff'],  alpha=0.6)
    plt.xlim(lower, upper)
    plt.xlabel("Complexity Difference (obf - ori)")
    plt.ylabel("Count")
    plt.axvline(0, color="red", linestyle="--", linewidth=1)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"{shift}_by_complexity_diff.pdf"))
    plt.close()

    print("âœ… LOC å’Œ Complexity åˆ†æå›¾å·²ç”Ÿæˆã€‚")

    # ---------------------------
    # æŒ‰æ¨¡å‹ç³»åˆ—åˆ†ç»„ï¼Œç”»æ•£ç‚¹å›¾
    # ---------------------------
    plt.figure(figsize=(6,4))

    series_markers = {
        "qwen": "o",       # åœ†ç‚¹
        "llama": "s",      # æ–¹å—
        "deepseek": "D",   # è±å½¢
        "openai": "^"      # ä¸‰è§’
    }

    series_colors = {
        "qwen": "tab:blue",
        "llama": "tab:green",
        "deepseek": "tab:orange",
        "openai": "tab:red"
    }

    texts = []

    unique_sizes = set()

    for series, models in SERIES_GROUPS.items():
        sizes = []
        counts = []
        labels = []

        for model in models:
            df_model = df_shift[df_shift["model"] == model]
            if df_model.empty:
                continue

            unique_sizes.add(get_model_size(model))
            sizes.append(get_model_size(model))
            counts.append(len(df_model))
            labels.append(LLM_ABBR_MAPPING[model])

        # ç”»æ•£ç‚¹
        plt.scatter(
            sizes, counts,
            label=series.capitalize(),
            color=series_colors[series],
            marker=series_markers[series],
            s=60, edgecolor="black", alpha=0.8
        )

        # åŠ æ–‡å­—
        for x, y, label in zip(sizes, counts, labels):
            texts.append(plt.text(x, y, label, ha="center", va="bottom", rotation=30))

    # è‡ªåŠ¨è°ƒæ•´æ–‡å­—é¿å…é‡å 
    adjust_text(texts, arrowprops=dict(arrowstyle='-', color='gray', alpha=0.5))

    # åŸå§‹åˆ»åº¦
    xticks = sorted(list(unique_sizes))
    xticklabels = [str(int(t)) for t in xticks[:-1]] + ["Unknown"]
    plt.xticks(xticks, xticklabels)

    plt.xlabel("Model size (B parameters)")
    plt.ylabel(f"{shift.capitalize()} count")
    plt.title(f"{shift.capitalize()} vs Model Size (by Series)")
    plt.legend(
        title="Series",
        loc="center left",
        bbox_to_anchor=(1.02, 0.5),  # å›¾å¤–å³è¾¹ï¼Œçºµå‘å±…ä¸­
        borderaxespad=0
    )
    plt.tight_layout()

    plt.grid(alpha=0.3)

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"{shift}_by_model_size.pdf"))
    plt.close()

    print("âœ… æŒ‰æ¨¡å‹ç³»åˆ—åˆ†ç»„çš„æ•£ç‚¹å›¾å·²ç”Ÿæˆã€‚")

    # # ---------------------------
    # # æŒ‰ REASONING_GROUPS ç»Ÿè®¡
    # # ---------------------------
    # reasoning_stats = []
    # for group_name, models in REASONING_GROUPS.items():
    #     df_group = df_shift[df_shift["model"].isin(models)]
    #     if df_group.empty:
    #         continue

    #     degrade_count = (df_group["shift_type"] == "degrade").sum()
    #     upgrade_count = (df_group["shift_type"] == "upgrade").sum()
    #     other_count = (df_group["shift_type"] == "other").sum()

    #     reasoning_stats.append({
    #         "group": group_name,
    #         "degrade": degrade_count,
    #         "upgrade": upgrade_count,
    #         "other": other_count,
    #         "total": len(df_group)
    #     })

    # df_reasoning_stats = pd.DataFrame(reasoning_stats).sort_values(by="total", ascending=False)
    # # è¾“å‡º CSV
    # df_reasoning_stats.to_csv(os.path.join(output_dir, f"{shift}_by_reasoning_group.csv"), index=False)
    # print(df_reasoning_stats)

    # # ç»˜åˆ¶æ¡å½¢å›¾
    # ax = df_reasoning_stats.set_index("group")[["degrade", "upgrade"]].plot(
    #     kind="bar", figsize=(6, 5), stacked=False, color=["tomato", "seagreen"], alpha=0.8
    # )
    # plt.title(f"{shift.capitalize()} by Reasoning Group")
    # plt.ylabel("Count")
    # plt.xticks(rotation=0)
    # for container in ax.containers:
    #     ax.bar_label(container, fmt="%d", label_type="edge", fontsize=9)
    # plt.tight_layout()
    # plt.savefig(os.path.join(output_dir, f"{shift}_by_reasoning_group.pdf"))
    # plt.close()




    #print(f"ğŸ‰ {shift} åˆ†æå…¨éƒ¨å®Œæˆï¼")



# ---------------------------
# ç»Ÿè®¡å„ç³»åˆ— degrade / upgrade / other æ•°é‡
# ---------------------------
series_stats = []

for series, models in SERIES_GROUPS.items():
    df_series = df[df["model"].isin(models)].copy()
    if df_series.empty:
        continue

    degrade_count = (df_series["shift_type"] == "degrade").sum()
    upgrade_count = (df_series["shift_type"] == "upgrade").sum()
    other_count   = (df_series["shift_type"] == "other").sum()

    series_stats.append({
        "series": series,
        "degrade": degrade_count,
        "upgrade": upgrade_count,
        "other": other_count,
        "total": len(df_series),
        "degrade_average_model": degrade_count / len(models),
        "upgrade_average_model": upgrade_count / len(models),
    })

# è½¬ DataFrame
df_series_stats = pd.DataFrame(series_stats)
# æŒ‰ degrade average æ•°é‡é™åºæ’åºï¼ˆå¯é€‰ï¼‰
df_series_stats = df_series_stats.sort_values(by="degrade_average_model", ascending=False)

# ---------------------------
# è¾“å‡º CSV
# ---------------------------
out_path = os.path.join(output_dir, "degrade_upgrade_by_model_series.csv")
df_series_stats.to_csv(out_path, index=False)
print(f"Series stats saved -> {out_path}")
print(df_series_stats)

df_plot = df_series_stats.set_index("series")[["degrade_average_model", "upgrade_average_model"]]
fig, ax = plt.subplots(figsize=(5, 3))


# è®¡ç®—æŸ±å­ä½ç½®
bar_width = 0.35
x = np.arange(len(df_plot.index))

# ç»˜åˆ¶æŸ±å­
bars_degrade = ax.bar(
    x - bar_width/2,
    df_plot["degrade_average_model"],
    width=bar_width,
    color=COLOR_STYLE["degrade"],
    hatch=HATCH_STYLE["degrade"],
    edgecolor="black",
    alpha=0.8,
    label="degrade"
)

bars_upgrade = ax.bar(
    x + bar_width/2,
    df_plot["upgrade_average_model"],
    width=bar_width,
    color=COLOR_STYLE["upgrade"],
    hatch=HATCH_STYLE["upgrade"],
    edgecolor="black",
    alpha=0.8,
    label="upgrade"
)

# è®¾ç½® x è½´æ ‡ç­¾
ax.set_xticks(x)
ax.set_xticklabels(df_plot.index, rotation=45, ha="right")
ax.set_xlabel("Model Series")
ax.set_ylabel("Average Count per Model")
#ax.set_title("Series Upgrade/Degrade Statistics")
ax.legend()

ymax = max(df_plot["degrade_average_model"].max(), df_plot["upgrade_average_model"].max())
ax.set_ylim(0, ymax * 1.2)

# ç»™æ¯ä¸ªæŸ±å­åŠ ä¸Šæ•°å­—
for bars in [bars_degrade, bars_upgrade]:
    ax.bar_label(bars, fmt="%d", label_type="edge", padding=5)

plt.tight_layout()
plt.savefig(os.path.join(output_dir, "degrade_upgrade_by_model_series.pdf"))
plt.close()